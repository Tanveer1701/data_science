{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:00:42.726330Z","iopub.execute_input":"2023-07-05T10:00:42.726741Z","iopub.status.idle":"2023-07-05T10:00:42.764919Z","shell.execute_reply.started":"2023-07-05T10:00:42.726708Z","shell.execute_reply":"2023-07-05T10:00:42.763861Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/sentiment-prediction-on-movie-reviews/movies.csv\n/kaggle/input/sentiment-prediction-on-movie-reviews/sample.csv\n/kaggle/input/sentiment-prediction-on-movie-reviews/train.csv\n/kaggle/input/sentiment-prediction-on-movie-reviews/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"#import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport string\nimport re","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:00:42.766761Z","iopub.execute_input":"2023-07-05T10:00:42.767547Z","iopub.status.idle":"2023-07-05T10:00:42.774096Z","shell.execute_reply.started":"2023-07-05T10:00:42.767489Z","shell.execute_reply":"2023-07-05T10:00:42.771594Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df_train=pd.read_csv(\"/kaggle/input/sentiment-prediction-on-movie-reviews/train.csv\")\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:00:42.775411Z","iopub.execute_input":"2023-07-05T10:00:42.775839Z","iopub.status.idle":"2023-07-05T10:00:43.777671Z","shell.execute_reply.started":"2023-07-05T10:00:42.775792Z","shell.execute_reply":"2023-07-05T10:00:43.776411Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                             movieid         reviewerName  \\\n0                                   marvelous_pirate       Benjamin Henry   \n1          tony_montana_frodo_baggins_v_rocky_balboa        Felicia Lopez   \n2  darth_vader_katniss_everdeen_sorcerer_donnie_d...  Mr. Charles Burgess   \n3                                 lara_croft_glimmer         Ryan Barrett   \n4  jason_bourne_surreal_the_terminator_indiana_jones     Alexander Glover   \n\n   isFrequentReviewer                                         reviewText  \\\n0               False  Henry Selick’s first movie since 2009’s Corali...   \n1               False  With a cast that reads like the Vogue Oscar pa...   \n2                True  Creed II does not give us anything but another...   \n3               False  I know what you're thinking, but this is no Li...   \n4               False  Director Fernando Meirelles tells the story wi...   \n\n  sentiment  \n0  POSITIVE  \n1  NEGATIVE  \n2  POSITIVE  \n3  POSITIVE  \n4  POSITIVE  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieid</th>\n      <th>reviewerName</th>\n      <th>isFrequentReviewer</th>\n      <th>reviewText</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>marvelous_pirate</td>\n      <td>Benjamin Henry</td>\n      <td>False</td>\n      <td>Henry Selick’s first movie since 2009’s Corali...</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tony_montana_frodo_baggins_v_rocky_balboa</td>\n      <td>Felicia Lopez</td>\n      <td>False</td>\n      <td>With a cast that reads like the Vogue Oscar pa...</td>\n      <td>NEGATIVE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>darth_vader_katniss_everdeen_sorcerer_donnie_d...</td>\n      <td>Mr. Charles Burgess</td>\n      <td>True</td>\n      <td>Creed II does not give us anything but another...</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>lara_croft_glimmer</td>\n      <td>Ryan Barrett</td>\n      <td>False</td>\n      <td>I know what you're thinking, but this is no Li...</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>jason_bourne_surreal_the_terminator_indiana_jones</td>\n      <td>Alexander Glover</td>\n      <td>False</td>\n      <td>Director Fernando Meirelles tells the story wi...</td>\n      <td>POSITIVE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#drop first 3 columns\ndf_train=df_train.drop(['movieid','reviewerName','isFrequentReviewer'],axis=1)\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:00:43.781084Z","iopub.execute_input":"2023-07-05T10:00:43.781797Z","iopub.status.idle":"2023-07-05T10:00:43.807158Z","shell.execute_reply.started":"2023-07-05T10:00:43.781750Z","shell.execute_reply":"2023-07-05T10:00:43.806070Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                          reviewText sentiment\n0  Henry Selick’s first movie since 2009’s Corali...  POSITIVE\n1  With a cast that reads like the Vogue Oscar pa...  NEGATIVE\n2  Creed II does not give us anything but another...  POSITIVE\n3  I know what you're thinking, but this is no Li...  POSITIVE\n4  Director Fernando Meirelles tells the story wi...  POSITIVE","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviewText</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Henry Selick’s first movie since 2009’s Corali...</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>With a cast that reads like the Vogue Oscar pa...</td>\n      <td>NEGATIVE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Creed II does not give us anything but another...</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I know what you're thinking, but this is no Li...</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Director Fernando Meirelles tells the story wi...</td>\n      <td>POSITIVE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#fill missing values with blank\ndf_train=df_train.fillna(\" \")\ndf_train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:00:43.809835Z","iopub.execute_input":"2023-07-05T10:00:43.810315Z","iopub.status.idle":"2023-07-05T10:00:44.081795Z","shell.execute_reply.started":"2023-07-05T10:00:43.810273Z","shell.execute_reply":"2023-07-05T10:00:44.080494Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"reviewText    0\nsentiment     0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"#editing reviewText column\n\n# Lowercasing\ndf_train['reviewText'] = df_train['reviewText'].str.lower()\n\n# Removing Punctuation\ndf_train['reviewText'] = df_train['reviewText'].apply(lambda text: re.sub(r'[^\\w\\s]', '', text))\n\n# Tokenization\ndf_train['reviewText'] = df_train['reviewText'].apply(lambda text: re.findall(r'\\w+', text))\n\n# Removing Stop Words\nstop_words = set(['the', 'is', 'and'])  # Add more stop words if needed\ndf_train['reviewText'] = df_train['reviewText'].apply(lambda tokens: [word for word in tokens if word not in stop_words])\n\n\n# Removing Numbers\ndf_train['reviewText'] = df_train['reviewText'].apply(lambda tokens: [word for word in tokens if not word.isdigit()])\n\n# Removing Extra Whitespaces\ndf_train['reviewText'] = df_train['reviewText'].apply(lambda tokens: [re.sub(r'\\s+', ' ', word) for word in tokens])\n\n# Joining Tokens back to Text\ndf_train['reviewText'] = df_train['reviewText'].apply(' '.join)\n\n# Handling Special Characters or URLs (Example: Removing URLs)\ndf_train['reviewText'] = df_train['reviewText'].apply(lambda text: re.sub(r'http\\S+', '', text))\n","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:00:44.083558Z","iopub.execute_input":"2023-07-05T10:00:44.084264Z","iopub.status.idle":"2023-07-05T10:00:57.428467Z","shell.execute_reply.started":"2023-07-05T10:00:44.084211Z","shell.execute_reply":"2023-07-05T10:00:57.427309Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#selecting X and y \nX=df_train['reviewText']\ny=df_train['sentiment']\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:00:57.429908Z","iopub.execute_input":"2023-07-05T10:00:57.430226Z","iopub.status.idle":"2023-07-05T10:00:57.436038Z","shell.execute_reply.started":"2023-07-05T10:00:57.430201Z","shell.execute_reply":"2023-07-05T10:00:57.434686Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#import necessary sklearn modules\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:00:57.437373Z","iopub.execute_input":"2023-07-05T10:00:57.437754Z","iopub.status.idle":"2023-07-05T10:00:58.194847Z","shell.execute_reply.started":"2023-07-05T10:00:57.437724Z","shell.execute_reply":"2023-07-05T10:00:58.193912Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:00:58.196571Z","iopub.execute_input":"2023-07-05T10:00:58.197287Z","iopub.status.idle":"2023-07-05T10:00:58.244605Z","shell.execute_reply.started":"2023-07-05T10:00:58.197246Z","shell.execute_reply":"2023-07-05T10:00:58.243566Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#vectorize the text using count vectorizer\nvectorizer=TfidfVectorizer()\nX_train_vec=vectorizer.fit_transform(X_train)\nX_test_vec=vectorizer.transform(X_test)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:00:58.250094Z","iopub.execute_input":"2023-07-05T10:00:58.250799Z","iopub.status.idle":"2023-07-05T10:01:03.547481Z","shell.execute_reply.started":"2023-07-05T10:00:58.250737Z","shell.execute_reply":"2023-07-05T10:01:03.546240Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Train Logistic Model\nmodel=LogisticRegression()\nmodel.fit(X_train_vec,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:01:03.549397Z","iopub.execute_input":"2023-07-05T10:01:03.549814Z","iopub.status.idle":"2023-07-05T10:01:14.964419Z","shell.execute_reply.started":"2023-07-05T10:01:03.549783Z","shell.execute_reply":"2023-07-05T10:01:14.963338Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"LogisticRegression()","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"#make predictions on test set\ny_pred=model.predict(X_test_vec)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:01:14.966122Z","iopub.execute_input":"2023-07-05T10:01:14.967381Z","iopub.status.idle":"2023-07-05T10:01:14.984630Z","shell.execute_reply.started":"2023-07-05T10:01:14.967338Z","shell.execute_reply":"2023-07-05T10:01:14.982796Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#calculate accuracy of the model\naccuracy=accuracy_score(y_test,y_pred)\nprint(\"Accuracy:\",accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:01:14.993808Z","iopub.execute_input":"2023-07-05T10:01:14.995565Z","iopub.status.idle":"2023-07-05T10:01:15.161443Z","shell.execute_reply.started":"2023-07-05T10:01:14.995474Z","shell.execute_reply":"2023-07-05T10:01:15.160250Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Accuracy: 0.7970324404030474\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import cross_val_score\n\n# Split the dataset into dependent(X) and independent variable(y)\nX = df_train['reviewText']\ny = df_train['sentiment']\n\n# Split the dataset into training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Construct a pipeline for text classification\npipeline = Pipeline([\n    ('vect', TfidfVectorizer()),\n    ('clf', LinearSVC())\n])\n\n# Set the parameters for the pipeline\nparameters = {\n    'vect__ngram_range': [(1, 1), (1, 2)],  # Try both unigrams and bigrams\n    'clf__C': [0.1, 1, 10]\n}\n\n# Perform randomized search to find the best parameters\nrandom_search = RandomizedSearchCV(pipeline, parameters, cv=5, n_iter=3)\nrandom_search.fit(X_train, y_train)\n\n# Get the best model\nbest_model = random_search.best_estimator_\n\n# Make predictions on the test set\ny_pred = best_model.predict(X_test)\n\n# Generate the classification report\nreport = classification_report(y_test, y_pred)\nprint('Classification Report:')\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:01:15.162573Z","iopub.execute_input":"2023-07-05T10:01:15.162908Z","iopub.status.idle":"2023-07-05T10:06:43.962978Z","shell.execute_reply.started":"2023-07-05T10:01:15.162881Z","shell.execute_reply":"2023-07-05T10:06:43.961894Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Classification Report:\n              precision    recall  f1-score   support\n\n    NEGATIVE       0.74      0.66      0.70     10696\n    POSITIVE       0.84      0.88      0.86     21856\n\n    accuracy                           0.81     32552\n   macro avg       0.79      0.77      0.78     32552\nweighted avg       0.81      0.81      0.81     32552\n\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\n\n#Naive Bayes\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import classification_report\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import cross_val_score\n\n# Split the dataset into dependent (X) and independent variable (y)\nX = df_train['reviewText']\ny = df_train['sentiment']\n\n# Split the dataset into training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Construct a pipeline for text classification\npipeline = Pipeline([\n    ('vect', TfidfVectorizer()),\n    ('clf', MultinomialNB())\n])\n\n# Set the parameters for the pipeline\nparameters = {\n    'vect__ngram_range': [(1, 1), (1, 2)],  # Try both unigrams and bigrams\n    'clf__alpha': [0.1, 1, 10]  # Try different values for the smoothing parameter alpha\n}\n\n# Perform randomized search to find the best parameters\nrandom_search = RandomizedSearchCV(pipeline, parameters, cv=5, n_iter=3)\nrandom_search.fit(X_train, y_train)\n\n# Get the best model\nbest_model = random_search.best_estimator_\n\n# Evaluate the model\ny_pred = best_model.predict(X_test)\nreport = classification_report(y_test, y_pred)\nprint(report)\n\"\"\"\n","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:06:43.965586Z","iopub.execute_input":"2023-07-05T10:06:43.966660Z","iopub.status.idle":"2023-07-05T10:06:43.976115Z","shell.execute_reply.started":"2023-07-05T10:06:43.966619Z","shell.execute_reply":"2023-07-05T10:06:43.974902Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"\"\\n\\n#Naive Bayes\\n\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.naive_bayes import MultinomialNB\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.model_selection import cross_val_score\\n\\n# Split the dataset into dependent (X) and independent variable (y)\\nX = df_train['reviewText']\\ny = df_train['sentiment']\\n\\n# Split the dataset into training and test set\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Construct a pipeline for text classification\\npipeline = Pipeline([\\n    ('vect', TfidfVectorizer()),\\n    ('clf', MultinomialNB())\\n])\\n\\n# Set the parameters for the pipeline\\nparameters = {\\n    'vect__ngram_range': [(1, 1), (1, 2)],  # Try both unigrams and bigrams\\n    'clf__alpha': [0.1, 1, 10]  # Try different values for the smoothing parameter alpha\\n}\\n\\n# Perform randomized search to find the best parameters\\nrandom_search = RandomizedSearchCV(pipeline, parameters, cv=5, n_iter=3)\\nrandom_search.fit(X_train, y_train)\\n\\n# Get the best model\\nbest_model = random_search.best_estimator_\\n\\n# Evaluate the model\\ny_pred = best_model.predict(X_test)\\nreport = classification_report(y_test, y_pred)\\nprint(report)\\n\""},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"\n#decision tree\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Split the dataset into dependent (X) and independent variable (y)\nX = df_train['reviewText']\ny = df_train['sentiment']\n\n# Split the dataset into training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Construct a pipeline for text classification\npipeline = Pipeline([\n    ('vect', TfidfVectorizer()),\n    ('clf', DecisionTreeClassifier())\n])\n\n# Set the parameters for the pipeline\nparameters = {\n    'vect__ngram_range': [(1, 1), (1, 2)],  # Try both unigrams and bigrams\n    'clf__max_depth': [None, 10, 20]  # Try different values for the maximum depth\n}\n\n# Perform randomized search to find the best parameters\nrandom_search = RandomizedSearchCV(pipeline, parameters, cv=5, n_iter=3)\nrandom_search.fit(X_train, y_train)\n\n# Get the best model\nbest_model = random_search.best_estimator_\n\n# Make predictions on the test set\ny_pred = best_model.predict(X_test)\n\n# Generate the classification report\nreport = classification_report(y_test, y_pred)\nprint(report)\n\"\"\"\n","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:06:43.977461Z","iopub.execute_input":"2023-07-05T10:06:43.977787Z","iopub.status.idle":"2023-07-05T10:06:43.995018Z","shell.execute_reply.started":"2023-07-05T10:06:43.977762Z","shell.execute_reply":"2023-07-05T10:06:43.994036Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"\"\\n#decision tree\\n\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.model_selection import RandomizedSearchCV\\n\\n# Split the dataset into dependent (X) and independent variable (y)\\nX = df_train['reviewText']\\ny = df_train['sentiment']\\n\\n# Split the dataset into training and test set\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Construct a pipeline for text classification\\npipeline = Pipeline([\\n    ('vect', TfidfVectorizer()),\\n    ('clf', DecisionTreeClassifier())\\n])\\n\\n# Set the parameters for the pipeline\\nparameters = {\\n    'vect__ngram_range': [(1, 1), (1, 2)],  # Try both unigrams and bigrams\\n    'clf__max_depth': [None, 10, 20]  # Try different values for the maximum depth\\n}\\n\\n# Perform randomized search to find the best parameters\\nrandom_search = RandomizedSearchCV(pipeline, parameters, cv=5, n_iter=3)\\nrandom_search.fit(X_train, y_train)\\n\\n# Get the best model\\nbest_model = random_search.best_estimator_\\n\\n# Make predictions on the test set\\ny_pred = best_model.predict(X_test)\\n\\n# Generate the classification report\\nreport = classification_report(y_test, y_pred)\\nprint(report)\\n\""},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"\n#SVM\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Split the dataset into dependent (X) and independent variable (y)\nX = df_train['reviewText']\ny = df_train['sentiment']\n\n# Split the dataset into training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Construct a pipeline for text classification\npipeline = Pipeline([\n    ('vect', TfidfVectorizer()),\n    ('clf', SVC())\n])\n\n# Set the parameters for the pipeline\nparameters = {\n    'vect__ngram_range': [(1, 1), (1, 2)],  # Try both unigrams and bigrams\n    'clf__C': [0.1, 1, 10]\n}\n\n# Perform randomized search to find the best parameters\nrandom_search = RandomizedSearchCV(pipeline, parameters, cv=5, n_iter=3)\nrandom_search.fit(X_train, y_train)\n\n# Get the best model\nbest_model = random_search.best_estimator_\n\n# Make predictions on the test set\ny_pred = best_model.predict(X_test)\n\n# Generate the classification report\nreport = classification_report(y_test, y_pred)\nprint(report)\n\"\"\"\n","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:06:43.996376Z","iopub.execute_input":"2023-07-05T10:06:43.996669Z","iopub.status.idle":"2023-07-05T10:06:44.011052Z","shell.execute_reply.started":"2023-07-05T10:06:43.996645Z","shell.execute_reply":"2023-07-05T10:06:44.010038Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"\"\\n#SVM\\n\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.svm import SVC\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.model_selection import RandomizedSearchCV\\n\\n# Split the dataset into dependent (X) and independent variable (y)\\nX = df_train['reviewText']\\ny = df_train['sentiment']\\n\\n# Split the dataset into training and test set\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Construct a pipeline for text classification\\npipeline = Pipeline([\\n    ('vect', TfidfVectorizer()),\\n    ('clf', SVC())\\n])\\n\\n# Set the parameters for the pipeline\\nparameters = {\\n    'vect__ngram_range': [(1, 1), (1, 2)],  # Try both unigrams and bigrams\\n    'clf__C': [0.1, 1, 10]\\n}\\n\\n# Perform randomized search to find the best parameters\\nrandom_search = RandomizedSearchCV(pipeline, parameters, cv=5, n_iter=3)\\nrandom_search.fit(X_train, y_train)\\n\\n# Get the best model\\nbest_model = random_search.best_estimator_\\n\\n# Make predictions on the test set\\ny_pred = best_model.predict(X_test)\\n\\n# Generate the classification report\\nreport = classification_report(y_test, y_pred)\\nprint(report)\\n\""},"metadata":{}}]},{"cell_type":"code","source":"#load the test file\n\ndf_test=pd.read_csv(\"/kaggle/input/sentiment-prediction-on-movie-reviews/test.csv\")\ndf_test.head()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:06:44.012215Z","iopub.execute_input":"2023-07-05T10:06:44.012690Z","iopub.status.idle":"2023-07-05T10:06:44.327648Z","shell.execute_reply.started":"2023-07-05T10:06:44.012663Z","shell.execute_reply":"2023-07-05T10:06:44.326582Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                               movieid     reviewerName  isTopCritic  \\\n0            legend_marty_mcfly_oracle         John Kim        False   \n1  terminator_katniss_everdeen_glimmer     Brian Chaney        False   \n2          james_bond_labyrinth_gollum  Danielle Parker        False   \n3            v_quest_han_solo_wondrous    Brittany Lane        False   \n4        enigma_hulk_surreal_starlight    Justin Willis        False   \n\n                                          reviewText  \n0  Green slowly cranks up the dread with style an...  \n1  Philip Noyce's direction is elegant and unforc...  \n2  It wouldn't do to say what path Maria ultimate...  \n3  Pig is not exactly the arthouse John Wick that...  \n4  An imaginative no-budget musical of sorts abou...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieid</th>\n      <th>reviewerName</th>\n      <th>isTopCritic</th>\n      <th>reviewText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>legend_marty_mcfly_oracle</td>\n      <td>John Kim</td>\n      <td>False</td>\n      <td>Green slowly cranks up the dread with style an...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>terminator_katniss_everdeen_glimmer</td>\n      <td>Brian Chaney</td>\n      <td>False</td>\n      <td>Philip Noyce's direction is elegant and unforc...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>james_bond_labyrinth_gollum</td>\n      <td>Danielle Parker</td>\n      <td>False</td>\n      <td>It wouldn't do to say what path Maria ultimate...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>v_quest_han_solo_wondrous</td>\n      <td>Brittany Lane</td>\n      <td>False</td>\n      <td>Pig is not exactly the arthouse John Wick that...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>enigma_hulk_surreal_starlight</td>\n      <td>Justin Willis</td>\n      <td>False</td>\n      <td>An imaginative no-budget musical of sorts abou...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#drop first 3 columns\ndf_test=df_test.drop(['movieid','reviewerName','isTopCritic'],axis=1)\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:06:44.329388Z","iopub.execute_input":"2023-07-05T10:06:44.330066Z","iopub.status.idle":"2023-07-05T10:06:44.343301Z","shell.execute_reply.started":"2023-07-05T10:06:44.330019Z","shell.execute_reply":"2023-07-05T10:06:44.341995Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"                                          reviewText\n0  Green slowly cranks up the dread with style an...\n1  Philip Noyce's direction is elegant and unforc...\n2  It wouldn't do to say what path Maria ultimate...\n3  Pig is not exactly the arthouse John Wick that...\n4  An imaginative no-budget musical of sorts abou...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviewText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Green slowly cranks up the dread with style an...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Philip Noyce's direction is elegant and unforc...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>It wouldn't do to say what path Maria ultimate...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Pig is not exactly the arthouse John Wick that...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>An imaginative no-budget musical of sorts abou...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#filling null values with blank\ndf_test['reviewText']=df_test['reviewText'].fillna(\" \")\ndf_test","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:09:59.524808Z","iopub.execute_input":"2023-07-05T10:09:59.525234Z","iopub.status.idle":"2023-07-05T10:09:59.549775Z","shell.execute_reply.started":"2023-07-05T10:09:59.525203Z","shell.execute_reply":"2023-07-05T10:09:59.548537Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"                                              reviewText\n0      Green slowly cranks up the dread with style an...\n1      Philip Noyce's direction is elegant and unforc...\n2      It wouldn't do to say what path Maria ultimate...\n3      Pig is not exactly the arthouse John Wick that...\n4      An imaginative no-budget musical of sorts abou...\n...                                                  ...\n55310  Ron Howard delivers an unconventional romantic...\n55311  As an oddball art film that openly invites you...\n55312  Nicholson wears his devilish grin from his fir...\n55313  It's hard not be entertained by two dozen of C...\n55314  Not clever enough for Smith fans, not gross en...\n\n[55315 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviewText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Green slowly cranks up the dread with style an...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Philip Noyce's direction is elegant and unforc...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>It wouldn't do to say what path Maria ultimate...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Pig is not exactly the arthouse John Wick that...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>An imaginative no-budget musical of sorts abou...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>55310</th>\n      <td>Ron Howard delivers an unconventional romantic...</td>\n    </tr>\n    <tr>\n      <th>55311</th>\n      <td>As an oddball art film that openly invites you...</td>\n    </tr>\n    <tr>\n      <th>55312</th>\n      <td>Nicholson wears his devilish grin from his fir...</td>\n    </tr>\n    <tr>\n      <th>55313</th>\n      <td>It's hard not be entertained by two dozen of C...</td>\n    </tr>\n    <tr>\n      <th>55314</th>\n      <td>Not clever enough for Smith fans, not gross en...</td>\n    </tr>\n  </tbody>\n</table>\n<p>55315 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_test_new = df_test['reviewText'].tolist()\n#vectorize the test data using the same Countvectorizer used for training\nX_test_vectorized=best_model.named_steps['vect'].transform(X_test_new)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:11:51.616129Z","iopub.execute_input":"2023-07-05T10:11:51.616661Z","iopub.status.idle":"2023-07-05T10:11:55.340693Z","shell.execute_reply.started":"2023-07-05T10:11:51.616485Z","shell.execute_reply":"2023-07-05T10:11:55.339692Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#make prediction on the test data\ntest_predictions= best_model.named_steps['clf'].predict(X_test_vectorized)\n\ntest_predictions\n","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:12:13.854064Z","iopub.execute_input":"2023-07-05T10:12:13.854462Z","iopub.status.idle":"2023-07-05T10:12:13.874465Z","shell.execute_reply.started":"2023-07-05T10:12:13.854433Z","shell.execute_reply":"2023-07-05T10:12:13.873658Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"array(['POSITIVE', 'POSITIVE', 'POSITIVE', ..., 'NEGATIVE', 'POSITIVE',\n       'NEGATIVE'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"#making a submission\nsubmission=pd.DataFrame(columns=['id','sentiment'])\nsubmission['id']=[i for i in range(len(test_predictions))]\nsubmission['sentiment']=test_predictions","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:12:19.916137Z","iopub.execute_input":"2023-07-05T10:12:19.916523Z","iopub.status.idle":"2023-07-05T10:12:20.012365Z","shell.execute_reply.started":"2023-07-05T10:12:19.916480Z","shell.execute_reply":"2023-07-05T10:12:20.011340Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"submission.shape\n","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:12:22.796308Z","iopub.execute_input":"2023-07-05T10:12:22.796928Z","iopub.status.idle":"2023-07-05T10:12:22.801927Z","shell.execute_reply.started":"2023-07-05T10:12:22.796891Z","shell.execute_reply":"2023-07-05T10:12:22.801199Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"(55315, 2)"},"metadata":{}}]},{"cell_type":"code","source":"submission.info","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:12:25.958227Z","iopub.execute_input":"2023-07-05T10:12:25.958658Z","iopub.status.idle":"2023-07-05T10:12:25.968573Z","shell.execute_reply.started":"2023-07-05T10:12:25.958621Z","shell.execute_reply":"2023-07-05T10:12:25.967542Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"<bound method DataFrame.info of           id sentiment\n0          0  POSITIVE\n1          1  POSITIVE\n2          2  POSITIVE\n3          3  POSITIVE\n4          4  POSITIVE\n...      ...       ...\n55310  55310  POSITIVE\n55311  55311  NEGATIVE\n55312  55312  NEGATIVE\n55313  55313  POSITIVE\n55314  55314  NEGATIVE\n\n[55315 rows x 2 columns]>"},"metadata":{}}]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:12:29.146223Z","iopub.execute_input":"2023-07-05T10:12:29.146696Z","iopub.status.idle":"2023-07-05T10:12:29.156996Z","shell.execute_reply.started":"2023-07-05T10:12:29.146652Z","shell.execute_reply":"2023-07-05T10:12:29.155844Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"   id sentiment\n0   0  POSITIVE\n1   1  POSITIVE\n2   2  POSITIVE\n3   3  POSITIVE\n4   4  POSITIVE","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>POSITIVE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>POSITIVE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#save the submission file\nsubmission.to_csv(\"submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-05T10:12:32.406096Z","iopub.execute_input":"2023-07-05T10:12:32.406532Z","iopub.status.idle":"2023-07-05T10:12:32.567057Z","shell.execute_reply.started":"2023-07-05T10:12:32.406483Z","shell.execute_reply":"2023-07-05T10:12:32.566188Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}